{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aif360'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maif360\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdultDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maif360\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryLabelDatasetMetric\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maif360\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reweighing\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'aif360'"
     ]
    }
   ],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import OptimPreproc\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import statistics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIF360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load adult Census Income Dataset\n",
    "### Possible protected attributes -> Sex and race, we have chosen sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 2809 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      " ['age', 'education-num', 'sex', 'capital-gain', 'hours-per-week', 'workclass=Federal-gov', 'workclass=Local-gov', 'workclass=Private', 'workclass=Self-emp-inc', 'workclass=Self-emp-not-inc', 'workclass=State-gov', 'workclass=Without-pay', 'marital-status=Divorced', 'marital-status=Married-AF-spouse', 'marital-status=Married-civ-spouse', 'marital-status=Married-spouse-absent', 'marital-status=Never-married', 'marital-status=Separated', 'marital-status=Widowed', 'occupation=Adm-clerical', 'occupation=Armed-Forces', 'occupation=Craft-repair', 'occupation=Exec-managerial', 'occupation=Farming-fishing', 'occupation=Handlers-cleaners', 'occupation=Machine-op-inspct', 'occupation=Other-service', 'occupation=Priv-house-serv', 'occupation=Prof-specialty', 'occupation=Protective-serv', 'occupation=Sales', 'occupation=Tech-support', 'occupation=Transport-moving']\n",
      "Labelname:\n",
      " ['income-per-year']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and set bias detection options,\n",
    "single_protected = ['sex']\n",
    "single_privileged = [['Male']]\n",
    "\n",
    "# We have dropped attributes that had <= 0.15 association with the true label, duplicate attribute 'eduction' (already included with numerical encoding), and 'realtionship' which is highly correlated with \"sex\", \"marital-status\", and \"age\")\n",
    "dataset_orig = AdultDataset(\n",
    "    protected_attribute_names=single_protected,\n",
    "    privileged_classes=single_privileged,\n",
    "    #categorical_features=[],\n",
    "    #features_to_keep=['age', 'education-num']\n",
    "    features_to_drop=['fnlwgt', 'native-country', 'race', 'capital-loss', 'education', 'relationship']\n",
    ")\n",
    "\n",
    "print(\"Feature names:\\n\", dataset_orig.feature_names)\n",
    "print(\"Labelname:\\n\", dataset_orig.label_names)\n",
    "\n",
    "# Split between train and test\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "# Sex as protected attribute encoded with 0 for females\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias mitigation during preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_orig_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisparate impact\u001b[39m\u001b[38;5;124m'\u001b[39m: metric_orig_train\u001b[38;5;241m.\u001b[39mdisparate_impact(),\n\u001b[0;32m      8\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean difference\u001b[39m\u001b[38;5;124m'\u001b[39m: metric_orig_train\u001b[38;5;241m.\u001b[39mmean_difference(),\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmoothed empirical differential fairness\u001b[39m\u001b[38;5;124m'\u001b[39m: metric_orig_train\u001b[38;5;241m.\u001b[39msmoothed_empirical_differential_fairness(concentration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     10\u001b[0m              }\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m---> 13\u001b[0m metrics_orig_train \u001b[38;5;241m=\u001b[39m binary_metrics(\u001b[43mdataset_orig_train\u001b[49m, unprivileged_groups, privileged_groups)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_orig_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute multiple binary label fairness metrics on the original training dataset\n",
    "def binary_metrics(dataset, unprivileged_groups, privileged_groups):\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups)\n",
    "\n",
    "    result = {'Disparate impact': metric_orig_train.disparate_impact(),\n",
    "              'Mean difference': metric_orig_train.mean_difference(),\n",
    "              'Smoothed empirical differential fairness': metric_orig_train.smoothed_empirical_differential_fairness(concentration=1.0)\n",
    "             }\n",
    "    return result\n",
    "\n",
    "metrics_orig_train = binary_metrics(dataset_orig_train, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Disparate impact': 0.9999999999999997,\n",
       " 'Mean difference': -8.326672684688674e-17,\n",
       " 'Smoothed empirical differential fairness': 5.16176875673402e-05}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mitigation: Preprocessing: Reweighing\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "dataset_transf_train_rw = RW.fit_transform(dataset_orig_train)\n",
    "\n",
    "# Compute fairness metrics again after the mitigation step\n",
    "binary_metrics(dataset_transf_train_rw, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Reweighing: weights the examples in each (group, label) combination differently to ensure fairness before classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Before mitigation:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact : 0.3543500702597874\n",
      "Mean difference : -0.2013421957302125\n",
      "Smoothed empirical differential fairness : 1.037158700736489\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### After mitigation:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact : 0.9999999999999997\n",
      "Mean difference : -8.326672684688674e-17\n",
      "Smoothed empirical differential fairness : 5.16176875673402e-05\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Reweighing: weights the examples in each (group, label) combination differently to ensure fairness before classification\"))\n",
    "\n",
    "display(Markdown(\"##### Before mitigation:\"))\n",
    "for key, value in metrics_orig_train.items():\n",
    "    print(key, ':', value)\n",
    "\n",
    "display(Markdown(\"##### After mitigation:\"))\n",
    "for key, value in binary_metrics(dataset_transf_train_rw, unprivileged_groups, privileged_groups).items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mitigation: Preprocessing: Disparate Impact Remover:\n",
    "DIR = DisparateImpactRemover(repair_level=1.0, sensitive_attribute='sex')\n",
    "dataset_transf_train_dir = DIR.fit_transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Disparate Impact Remover: edits feature values increase group fairness while preserving rank-ordering within groups"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Before mitigation:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact : 0.3543500702597874\n",
      "Mean difference : -0.2013421957302125\n",
      "Smoothed empirical differential fairness : 1.037158700736489\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### After mitigation:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact : 0.3543500702597874\n",
      "Mean difference : -0.2013421957302125\n",
      "Smoothed empirical differential fairness : 1.037158700736489\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Disparate Impact Remover: edits feature values increase group fairness while preserving rank-ordering within groups\"))\n",
    "\n",
    "display(Markdown(\"##### Before mitigation:\"))\n",
    "for key, value in metrics_orig_train.items():\n",
    "    print(key, ':', value)\n",
    "\n",
    "display(Markdown(\"##### After mitigation:\"))\n",
    "for key, value in binary_metrics(dataset_transf_train_dir, unprivileged_groups, privileged_groups).items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bias mitigation during inprocessing: Adversarial debiasing:\n",
    "learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions [1]. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a plain classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 5.807417\n",
      "epoch 0; iter: 200; batch classifier loss: 7.163935\n",
      "epoch 1; iter: 0; batch classifier loss: 2.698117\n",
      "epoch 1; iter: 200; batch classifier loss: 2.462013\n",
      "epoch 2; iter: 0; batch classifier loss: 2.410797\n",
      "epoch 2; iter: 200; batch classifier loss: 4.004699\n",
      "epoch 3; iter: 0; batch classifier loss: 0.970145\n",
      "epoch 3; iter: 200; batch classifier loss: 1.177792\n",
      "epoch 4; iter: 0; batch classifier loss: 1.884840\n",
      "epoch 4; iter: 200; batch classifier loss: 2.031663\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491326\n",
      "epoch 5; iter: 200; batch classifier loss: 1.327786\n",
      "epoch 6; iter: 0; batch classifier loss: 2.038118\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804699\n",
      "epoch 7; iter: 0; batch classifier loss: 1.639204\n",
      "epoch 7; iter: 200; batch classifier loss: 0.318860\n",
      "epoch 8; iter: 0; batch classifier loss: 0.406714\n",
      "epoch 8; iter: 200; batch classifier loss: 0.386706\n",
      "epoch 9; iter: 0; batch classifier loss: 1.019848\n",
      "epoch 9; iter: 200; batch classifier loss: 0.568275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.678232\n",
      "epoch 10; iter: 200; batch classifier loss: 3.048346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410153\n",
      "epoch 11; iter: 200; batch classifier loss: 0.387998\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511427\n",
      "epoch 12; iter: 200; batch classifier loss: 0.336384\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372388\n",
      "epoch 13; iter: 200; batch classifier loss: 0.322251\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463377\n",
      "epoch 14; iter: 200; batch classifier loss: 0.360643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398279\n",
      "epoch 15; iter: 200; batch classifier loss: 0.301411\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370130\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327261\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288818\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346109\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389389\n",
      "epoch 18; iter: 200; batch classifier loss: 0.418248\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269089\n",
      "epoch 19; iter: 200; batch classifier loss: 0.606141\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473354\n",
      "epoch 20; iter: 200; batch classifier loss: 0.391460\n",
      "epoch 21; iter: 0; batch classifier loss: 0.422813\n",
      "epoch 21; iter: 200; batch classifier loss: 0.329672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289549\n",
      "epoch 22; iter: 200; batch classifier loss: 0.314247\n",
      "epoch 23; iter: 0; batch classifier loss: 0.324263\n",
      "epoch 23; iter: 200; batch classifier loss: 0.289062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265424\n",
      "epoch 24; iter: 200; batch classifier loss: 0.322431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302978\n",
      "epoch 25; iter: 200; batch classifier loss: 0.281859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.313229\n",
      "epoch 26; iter: 200; batch classifier loss: 0.491318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246840\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310375\n",
      "epoch 28; iter: 0; batch classifier loss: 0.316840\n",
      "epoch 28; iter: 200; batch classifier loss: 0.304260\n",
      "epoch 29; iter: 0; batch classifier loss: 0.308525\n",
      "epoch 29; iter: 200; batch classifier loss: 0.313343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.278940\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335364\n",
      "epoch 31; iter: 0; batch classifier loss: 0.259191\n",
      "epoch 31; iter: 200; batch classifier loss: 0.329519\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291344\n",
      "epoch 32; iter: 200; batch classifier loss: 0.297095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310046\n",
      "epoch 33; iter: 200; batch classifier loss: 0.280966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292582\n",
      "epoch 34; iter: 200; batch classifier loss: 0.335043\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300831\n",
      "epoch 35; iter: 200; batch classifier loss: 0.380835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.359013\n",
      "epoch 36; iter: 200; batch classifier loss: 0.362037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.272813\n",
      "epoch 37; iter: 200; batch classifier loss: 0.420096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.314992\n",
      "epoch 38; iter: 200; batch classifier loss: 0.577308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438805\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269555\n",
      "epoch 40; iter: 200; batch classifier loss: 0.262929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313594\n",
      "epoch 41; iter: 200; batch classifier loss: 0.310259\n",
      "epoch 42; iter: 0; batch classifier loss: 0.305832\n",
      "epoch 42; iter: 200; batch classifier loss: 0.337536\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328412\n",
      "epoch 43; iter: 200; batch classifier loss: 0.361656\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323779\n",
      "epoch 44; iter: 200; batch classifier loss: 0.314700\n",
      "epoch 45; iter: 0; batch classifier loss: 0.323511\n",
      "epoch 45; iter: 200; batch classifier loss: 0.329886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.361755\n",
      "epoch 46; iter: 200; batch classifier loss: 0.189143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.342015\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258219\n",
      "epoch 48; iter: 200; batch classifier loss: 0.328110\n",
      "epoch 49; iter: 0; batch classifier loss: 0.297746\n",
      "epoch 49; iter: 200; batch classifier loss: 0.363216\n"
     ]
    }
   ],
   "source": [
    "# Learn plain classifier without debiasing\n",
    "# https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "if sess:\n",
    "    sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()\n",
    "clf = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)\n",
    "clf.fit(dataset_orig_train)\n",
    "#y_pred = clf.predict(dataset_orig_test.features)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = clf.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = clf.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a debiasing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 105.667290; batch adversarial loss: 0.855942\n",
      "epoch 0; iter: 200; batch classifier loss: 6.655151; batch adversarial loss: 0.756046\n",
      "epoch 1; iter: 0; batch classifier loss: 10.932810; batch adversarial loss: 0.807950\n",
      "epoch 1; iter: 200; batch classifier loss: 7.798539; batch adversarial loss: 0.662345\n",
      "epoch 2; iter: 0; batch classifier loss: 3.995960; batch adversarial loss: 0.688334\n",
      "epoch 2; iter: 200; batch classifier loss: 5.578463; batch adversarial loss: 0.650072\n",
      "epoch 3; iter: 0; batch classifier loss: 10.116468; batch adversarial loss: 0.637887\n",
      "epoch 3; iter: 200; batch classifier loss: 1.575187; batch adversarial loss: 0.611195\n",
      "epoch 4; iter: 0; batch classifier loss: 4.453220; batch adversarial loss: 0.671072\n",
      "epoch 4; iter: 200; batch classifier loss: 3.543374; batch adversarial loss: 0.635989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.774815; batch adversarial loss: 0.687947\n",
      "epoch 5; iter: 200; batch classifier loss: 2.594435; batch adversarial loss: 0.624740\n",
      "epoch 6; iter: 0; batch classifier loss: 1.241345; batch adversarial loss: 0.583366\n",
      "epoch 6; iter: 200; batch classifier loss: 0.863850; batch adversarial loss: 0.601183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420315; batch adversarial loss: 0.688266\n",
      "epoch 7; iter: 200; batch classifier loss: 0.400096; batch adversarial loss: 0.641534\n",
      "epoch 8; iter: 0; batch classifier loss: 1.479709; batch adversarial loss: 0.618190\n",
      "epoch 8; iter: 200; batch classifier loss: 0.574372; batch adversarial loss: 0.580982\n",
      "epoch 9; iter: 0; batch classifier loss: 1.018712; batch adversarial loss: 0.643799\n",
      "epoch 9; iter: 200; batch classifier loss: 0.644765; batch adversarial loss: 0.600429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.990478; batch adversarial loss: 0.619350\n",
      "epoch 10; iter: 200; batch classifier loss: 0.593189; batch adversarial loss: 0.590836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508701; batch adversarial loss: 0.649052\n",
      "epoch 11; iter: 200; batch classifier loss: 0.582827; batch adversarial loss: 0.617925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469438; batch adversarial loss: 0.614250\n",
      "epoch 12; iter: 200; batch classifier loss: 0.443607; batch adversarial loss: 0.606517\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593300; batch adversarial loss: 0.638699\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440661; batch adversarial loss: 0.623696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478899; batch adversarial loss: 0.628642\n",
      "epoch 14; iter: 200; batch classifier loss: 0.457056; batch adversarial loss: 0.602465\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529009; batch adversarial loss: 0.592314\n",
      "epoch 15; iter: 200; batch classifier loss: 0.518310; batch adversarial loss: 0.613198\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.619762\n",
      "epoch 16; iter: 200; batch classifier loss: 0.511102; batch adversarial loss: 0.587791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307480; batch adversarial loss: 0.631282\n",
      "epoch 17; iter: 200; batch classifier loss: 0.454935; batch adversarial loss: 0.603861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419763; batch adversarial loss: 0.623416\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383531; batch adversarial loss: 0.580715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342738; batch adversarial loss: 0.621056\n",
      "epoch 19; iter: 200; batch classifier loss: 0.343058; batch adversarial loss: 0.574525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447263; batch adversarial loss: 0.616781\n",
      "epoch 20; iter: 200; batch classifier loss: 0.306838; batch adversarial loss: 0.565687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311157; batch adversarial loss: 0.634948\n",
      "epoch 21; iter: 200; batch classifier loss: 0.413851; batch adversarial loss: 0.560212\n",
      "epoch 22; iter: 0; batch classifier loss: 0.353260; batch adversarial loss: 0.620407\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334654; batch adversarial loss: 0.574214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354349; batch adversarial loss: 0.594241\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374439; batch adversarial loss: 0.591130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325746; batch adversarial loss: 0.592000\n",
      "epoch 24; iter: 200; batch classifier loss: 0.501993; batch adversarial loss: 0.629855\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333740; batch adversarial loss: 0.607840\n",
      "epoch 25; iter: 200; batch classifier loss: 0.297310; batch adversarial loss: 0.625920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.348885; batch adversarial loss: 0.536905\n",
      "epoch 26; iter: 200; batch classifier loss: 0.259156; batch adversarial loss: 0.639324\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310737; batch adversarial loss: 0.565741\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329312; batch adversarial loss: 0.536320\n",
      "epoch 28; iter: 0; batch classifier loss: 0.271565; batch adversarial loss: 0.569392\n",
      "epoch 28; iter: 200; batch classifier loss: 0.327000; batch adversarial loss: 0.622964\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343799; batch adversarial loss: 0.626436\n",
      "epoch 29; iter: 200; batch classifier loss: 0.286879; batch adversarial loss: 0.642056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336350; batch adversarial loss: 0.622245\n",
      "epoch 30; iter: 200; batch classifier loss: 0.358972; batch adversarial loss: 0.562840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.339758; batch adversarial loss: 0.618464\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331540; batch adversarial loss: 0.574279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.353846; batch adversarial loss: 0.601683\n",
      "epoch 32; iter: 200; batch classifier loss: 0.355241; batch adversarial loss: 0.615449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330047; batch adversarial loss: 0.565490\n",
      "epoch 33; iter: 200; batch classifier loss: 0.311343; batch adversarial loss: 0.613558\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380844; batch adversarial loss: 0.609326\n",
      "epoch 34; iter: 200; batch classifier loss: 0.305435; batch adversarial loss: 0.560929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.338528; batch adversarial loss: 0.623229\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347168; batch adversarial loss: 0.619557\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341614; batch adversarial loss: 0.644722\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327427; batch adversarial loss: 0.636204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381031; batch adversarial loss: 0.604551\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341959; batch adversarial loss: 0.648501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.316701; batch adversarial loss: 0.564693\n",
      "epoch 38; iter: 200; batch classifier loss: 0.329655; batch adversarial loss: 0.637415\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309115; batch adversarial loss: 0.628008\n",
      "epoch 39; iter: 200; batch classifier loss: 0.378563; batch adversarial loss: 0.582520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.263802; batch adversarial loss: 0.655527\n",
      "epoch 40; iter: 200; batch classifier loss: 0.396012; batch adversarial loss: 0.653308\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413995; batch adversarial loss: 0.643959\n",
      "epoch 41; iter: 200; batch classifier loss: 0.352726; batch adversarial loss: 0.612276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.333220; batch adversarial loss: 0.642612\n",
      "epoch 42; iter: 200; batch classifier loss: 0.373309; batch adversarial loss: 0.628992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.277189; batch adversarial loss: 0.622919\n",
      "epoch 43; iter: 200; batch classifier loss: 0.296071; batch adversarial loss: 0.679703\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369003; batch adversarial loss: 0.591501\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389958; batch adversarial loss: 0.648713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318563; batch adversarial loss: 0.592864\n",
      "epoch 45; iter: 200; batch classifier loss: 0.350127; batch adversarial loss: 0.580022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210598; batch adversarial loss: 0.634591\n",
      "epoch 46; iter: 200; batch classifier loss: 0.305697; batch adversarial loss: 0.580900\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286418; batch adversarial loss: 0.592897\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403489; batch adversarial loss: 0.667638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299556; batch adversarial loss: 0.654760\n",
      "epoch 48; iter: 200; batch classifier loss: 0.317408; batch adversarial loss: 0.633405\n",
      "epoch 49; iter: 0; batch classifier loss: 0.305310; batch adversarial loss: 0.654523\n",
      "epoch 49; iter: 200; batch classifier loss: 0.459449; batch adversarial loss: 0.659857\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# Learn parameters with debias set to True\n",
    "debiased_clf = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "\n",
    "debiased_clf.fit(dataset_orig_train)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_clf.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_clf.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.206872\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.201568\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.095770\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.092306\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.843374\n",
      "Test set: Balanced classification accuracy = 0.773292\n",
      "Test set: Disparate impact = 0.302917\n",
      "Test set: Equal opportunity difference = -0.140927\n",
      "Test set: Average odds difference = -0.116580\n",
      "Test set: Theil_index = 0.120074\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.838668\n",
      "Test set: Balanced classification accuracy = 0.736977\n",
      "Test set: Disparate impact = 0.556197\n",
      "Test set: Equal opportunity difference = 0.097225\n",
      "Test set: Average odds difference = 0.039272\n",
      "Test set: Theil_index = 0.141963\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "#####\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### What types of bias mitigation algorithm are available?\n",
    "\n",
    "Bias mitigation algorithms are typically separated into preprocessing, inpprocessing,and postprocessig. Another possible topology is based on the fairness metrics they mitigate.\n",
    "\n",
    "### Do you see a difference between the different types of algorithms?\n",
    "\n",
    "The step of processing is very crucial in defining the possibilities and limitations for a algorithmic bias mitigation - algorithms at different steps act very differently. However,the algorithms within each category can also be very different.\n",
    "\n",
    "### What changes are you able to witness?\n",
    "\n",
    "The preprocessing algorithm reweighing seems to have a negative impact on fairness, while the preprocessing algorithm disparate impact remover has no effect at all. This suggests that something has gone wrong in our way of applying these algorithms, however, we can't seem to find the bug at the moment.\n",
    "\n",
    "The inprocessing algorithm adversarial debiasing has worked well on debiaing the mean outcomes between the two groups, while not affecting the performance of the classification model much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Tools Overview\n",
    "\n",
    "There's quite a few other Fairness Tools available, although AI Fairness 360 appears to be the most popular and most developed open source projects available.\n",
    "However, we could not find much information on these tools being used commercially. The Fairlearn toolkit, developed by Microsoft, seems to have been used internally by them, but it is unclear in which capacity. Rather, we found in our research that the adoption of fairness toolkits seems to be lagging behind. To quote one [article](https://ukfinancialservicesinsights.deloitte.com/post/102gh6a/landscape-and-gaps-in-open-source-fairness-toolkits): \"Only 54% survey respondents had used any open source fairness toolkit before, despite the study's sampling of groups with likely exposure to fairness-related concerns.\"\n",
    "We also read this [paper](https://www.researchgate.net/publication/356985512_A_Framework_for_Fairness_A_Systematic_Review_of_Existing_Fair_AI_Solutions) which isn't practically relevant for the section, but still quite interesting.\n",
    "\n",
    "**Aequitas**\n",
    "\n",
    "Aequitas is another Open Source Toolkit with a focus on analysing und visualising fairness metrics. Using Aequitas, you can generate a \"Bias Report\" based on your input data with the following criterias:\n",
    "\n",
    "Equal Parity - Each group is represented equally  \n",
    "Proportional Parity - Each group is represented proportional to their representation overall population  \n",
    "False Positive Parity - Each group has proportionally equal false positive errors made by the model.  \n",
    "False negative Parity - Each group has proportionally equal false negative errors made by the model.  \n",
    "\n",
    "The report gives back a table judging each Attribute value as either fair or unfair based on these metrics (and a weighted combined score). \n",
    "\n",
    "This is visually very appealing, and certainly a great tool for analysing problems with fairness in a given dataset, however Aequitas doesn't include tools to combat problems with fairness.\n",
    "\n",
    "**FairSight**\n",
    "\n",
    "From their github repo: \"FairSight is a viable fair decision making system to assist decision makers in achieving fair decision making through the machine learning workflow.\"\n",
    "\n",
    "This tool really takes the cake on a visualisation level - You get a beautiful colored dashboard with lots of relevant metrics for fairness after feeding it with input data. However, it also does not contain the tooling to actually change the data or model to become more fair. Again, from the github repo: \n",
    "\n",
    "\"FairSight is developed on top of FairDM, a general fair decision making framework. Our framework is a model-agnostic framework with its goal to provide a fairness pipeline to guide the examination of fairness at each step (from input to output) in the workflow.\"\n",
    "\n",
    "**Fairlearn**\n",
    "\n",
    "Fairlearn is a python package both for assessing and mitigating issues with unfairness. It contains some algorithms for mitigating unfairness, including Correlation Remover for preprocessing and various kinds of UtilityParity-Algorithms like Demographic Parity, True/False Positive Rate Parity, Equalized Odds, and Error Rate Parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
