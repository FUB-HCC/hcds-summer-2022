{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import OptimPreproc\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import statistics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AIF360"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load adult Census Income Dataset\n",
    "### Possible protected attributes -> Sex and race, we have chosen sex"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 2809 rows removed from AdultDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      " ['age', 'education-num', 'sex', 'capital-gain', 'hours-per-week', 'workclass=Federal-gov', 'workclass=Local-gov', 'workclass=Private', 'workclass=Self-emp-inc', 'workclass=Self-emp-not-inc', 'workclass=State-gov', 'workclass=Without-pay', 'marital-status=Divorced', 'marital-status=Married-AF-spouse', 'marital-status=Married-civ-spouse', 'marital-status=Married-spouse-absent', 'marital-status=Never-married', 'marital-status=Separated', 'marital-status=Widowed', 'occupation=Adm-clerical', 'occupation=Armed-Forces', 'occupation=Craft-repair', 'occupation=Exec-managerial', 'occupation=Farming-fishing', 'occupation=Handlers-cleaners', 'occupation=Machine-op-inspct', 'occupation=Other-service', 'occupation=Priv-house-serv', 'occupation=Prof-specialty', 'occupation=Protective-serv', 'occupation=Sales', 'occupation=Tech-support', 'occupation=Transport-moving']\n",
      "Labelname:\n",
      " ['income-per-year']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and set bias detection options,\n",
    "single_protected = ['sex']\n",
    "single_privileged = [['Male']]\n",
    "\n",
    "# We have dropped attributes that had <= 0.15 association with the true label, duplicate attribute 'eduction' (already included with numerical encoding), and 'realtionship' which is highly correlated with \"sex\", \"marital-status\", and \"age\")\n",
    "dataset_orig = AdultDataset(\n",
    "    protected_attribute_names=single_protected,\n",
    "    privileged_classes=single_privileged,\n",
    "    #categorical_features=[],\n",
    "    #features_to_keep=['age', 'education-num']\n",
    "    features_to_drop=['fnlwgt', 'native-country', 'race', 'capital-loss', 'education', 'relationship']\n",
    ")\n",
    "\n",
    "print(\"Feature names:\\n\", dataset_orig.feature_names)\n",
    "print(\"Labelname:\\n\", dataset_orig.label_names)\n",
    "\n",
    "# Split between train and test\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "# Sex as protected attribute encoded with 0 for females\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute multiple binary label fairness metrics on the original training dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Disparate impact': 0.3543500702597874,\n 'Mean difference': -0.2013421957302125,\n 'Smoothed empirical differential fairness': 1.037158700736489}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_metrics(dataset, unprivileged_groups, privileged_groups):\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups)\n",
    "\n",
    "    result = {'Disparate impact': metric_orig_train.disparate_impact(),\n",
    "              'Mean difference': metric_orig_train.mean_difference(),\n",
    "              'Smoothed empirical differential fairness': metric_orig_train.smoothed_empirical_differential_fairness(concentration=1.0)\n",
    "             }\n",
    "    return result\n",
    "\n",
    "binary_metrics(dataset_orig_train, unprivileged_groups, privileged_groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try to mitigate bias using bias mitigation algorithms for preprocessing\n",
    "### Then compute fairness metrics again after the mitigation step and compare with premitigation metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Reweighing: weights the examples in each (group, label) combination differently to ensure fairness before classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2061472606.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/gb/_z6m1yxd2cl20x7frgyy43tc0000gn/T/ipykernel_14165/2061472606.py\"\u001B[0;36m, line \u001B[0;32m2\u001B[0m\n\u001B[0;31m    weights the examples in each (group, label) combination differently to ensure fairness before classification\u001B[0m\n\u001B[0m            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Disparate impact': 0.9999999999999997,\n 'Mean difference': -8.326672684688674e-17,\n 'Smoothed empirical differential fairness': 5.16176875673402e-05}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mitigation\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "dataset_transf_train_rw = RW.fit_transform(dataset_orig_train)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)\n",
    "\n",
    "# Compute fairness metrics again after the mitigation step\n",
    "binary_metrics(dataset_transf_train_rw, unprivileged_groups, privileged_groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Disparate Impact Remover: edits feature values increase group fairness while preserving rank-ordering within groups"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Disparate impact': 0.3543500702597874,\n 'Mean difference': -0.2013421957302125,\n 'Smoothed empirical differential fairness': 1.037158700736489}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mitigation\n",
    "DIR = DisparateImpactRemover(repair_level=1.0, sensitive_attribute='sex')\n",
    "dataset_transf_train_dir = DIR.fit_transform(dataset_orig_train)\n",
    "\n",
    "# Compute fairness metrics again after the mitigation step\n",
    "binary_metrics(dataset_transf_train_dir, unprivileged_groups, privileged_groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train a plain classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 5.807417\n",
      "epoch 0; iter: 200; batch classifier loss: 7.163935\n",
      "epoch 1; iter: 0; batch classifier loss: 2.698117\n",
      "epoch 1; iter: 200; batch classifier loss: 2.462013\n",
      "epoch 2; iter: 0; batch classifier loss: 2.410797\n",
      "epoch 2; iter: 200; batch classifier loss: 4.004699\n",
      "epoch 3; iter: 0; batch classifier loss: 0.970145\n",
      "epoch 3; iter: 200; batch classifier loss: 1.177792\n",
      "epoch 4; iter: 0; batch classifier loss: 1.884840\n",
      "epoch 4; iter: 200; batch classifier loss: 2.031663\n",
      "epoch 5; iter: 0; batch classifier loss: 0.491326\n",
      "epoch 5; iter: 200; batch classifier loss: 1.327786\n",
      "epoch 6; iter: 0; batch classifier loss: 2.038118\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804699\n",
      "epoch 7; iter: 0; batch classifier loss: 1.639204\n",
      "epoch 7; iter: 200; batch classifier loss: 0.318860\n",
      "epoch 8; iter: 0; batch classifier loss: 0.406714\n",
      "epoch 8; iter: 200; batch classifier loss: 0.386706\n",
      "epoch 9; iter: 0; batch classifier loss: 1.019848\n",
      "epoch 9; iter: 200; batch classifier loss: 0.568275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.678232\n",
      "epoch 10; iter: 200; batch classifier loss: 3.048346\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410153\n",
      "epoch 11; iter: 200; batch classifier loss: 0.387998\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511427\n",
      "epoch 12; iter: 200; batch classifier loss: 0.336384\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372388\n",
      "epoch 13; iter: 200; batch classifier loss: 0.322251\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463377\n",
      "epoch 14; iter: 200; batch classifier loss: 0.360643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398279\n",
      "epoch 15; iter: 200; batch classifier loss: 0.301411\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370130\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327261\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288818\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346109\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389389\n",
      "epoch 18; iter: 200; batch classifier loss: 0.418248\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269089\n",
      "epoch 19; iter: 200; batch classifier loss: 0.606141\n",
      "epoch 20; iter: 0; batch classifier loss: 0.473354\n",
      "epoch 20; iter: 200; batch classifier loss: 0.391460\n",
      "epoch 21; iter: 0; batch classifier loss: 0.422813\n",
      "epoch 21; iter: 200; batch classifier loss: 0.329672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289549\n",
      "epoch 22; iter: 200; batch classifier loss: 0.314247\n",
      "epoch 23; iter: 0; batch classifier loss: 0.324263\n",
      "epoch 23; iter: 200; batch classifier loss: 0.289062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265424\n",
      "epoch 24; iter: 200; batch classifier loss: 0.322431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302978\n",
      "epoch 25; iter: 200; batch classifier loss: 0.281859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.313229\n",
      "epoch 26; iter: 200; batch classifier loss: 0.491318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246840\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310375\n",
      "epoch 28; iter: 0; batch classifier loss: 0.316840\n",
      "epoch 28; iter: 200; batch classifier loss: 0.304260\n",
      "epoch 29; iter: 0; batch classifier loss: 0.308525\n",
      "epoch 29; iter: 200; batch classifier loss: 0.313343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.278940\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335364\n",
      "epoch 31; iter: 0; batch classifier loss: 0.259191\n",
      "epoch 31; iter: 200; batch classifier loss: 0.329519\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291344\n",
      "epoch 32; iter: 200; batch classifier loss: 0.297095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310046\n",
      "epoch 33; iter: 200; batch classifier loss: 0.280966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292582\n",
      "epoch 34; iter: 200; batch classifier loss: 0.335043\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300831\n",
      "epoch 35; iter: 200; batch classifier loss: 0.380835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.359013\n",
      "epoch 36; iter: 200; batch classifier loss: 0.362037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.272813\n",
      "epoch 37; iter: 200; batch classifier loss: 0.420096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.314992\n",
      "epoch 38; iter: 200; batch classifier loss: 0.577308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.438805\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269555\n",
      "epoch 40; iter: 200; batch classifier loss: 0.262929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313594\n",
      "epoch 41; iter: 200; batch classifier loss: 0.310259\n",
      "epoch 42; iter: 0; batch classifier loss: 0.305832\n",
      "epoch 42; iter: 200; batch classifier loss: 0.337536\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328412\n",
      "epoch 43; iter: 200; batch classifier loss: 0.361656\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323779\n",
      "epoch 44; iter: 200; batch classifier loss: 0.314700\n",
      "epoch 45; iter: 0; batch classifier loss: 0.323511\n",
      "epoch 45; iter: 200; batch classifier loss: 0.329886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.361755\n",
      "epoch 46; iter: 200; batch classifier loss: 0.189143\n",
      "epoch 47; iter: 0; batch classifier loss: 0.342015\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354038\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258219\n",
      "epoch 48; iter: 200; batch classifier loss: 0.328110\n",
      "epoch 49; iter: 0; batch classifier loss: 0.297746\n",
      "epoch 49; iter: 200; batch classifier loss: 0.363216\n"
     ]
    }
   ],
   "source": [
    "# Learn plain classifier without debiasing\n",
    "# https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "if sess:\n",
    "    sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()\n",
    "clf = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)\n",
    "clf.fit(dataset_orig_train)\n",
    "#y_pred = clf.predict(dataset_orig_test.features)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = clf.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = clf.predict(dataset_orig_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try to mitigate bias using bias mitigation algorithms for inporcessing\n",
    "### Then compute pre- and post- fairness metrics and compare them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Plain model - without debiasing - dataset metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.206872\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.201568\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Plain model - without debiasing - classification metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.843374\n",
      "Test set: Balanced classification accuracy = 0.773292\n",
      "Test set: Disparate impact = 0.302917\n",
      "Test set: Equal opportunity difference = -0.140927\n",
      "Test set: Average odds difference = -0.116580\n",
      "Test set: Theil_index = 0.120074\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 105.667290; batch adversarial loss: 0.855942\n",
      "epoch 0; iter: 200; batch classifier loss: 6.655151; batch adversarial loss: 0.756046\n",
      "epoch 1; iter: 0; batch classifier loss: 10.932810; batch adversarial loss: 0.807950\n",
      "epoch 1; iter: 200; batch classifier loss: 7.798539; batch adversarial loss: 0.662345\n",
      "epoch 2; iter: 0; batch classifier loss: 3.995960; batch adversarial loss: 0.688334\n",
      "epoch 2; iter: 200; batch classifier loss: 5.578463; batch adversarial loss: 0.650072\n",
      "epoch 3; iter: 0; batch classifier loss: 10.116468; batch adversarial loss: 0.637887\n",
      "epoch 3; iter: 200; batch classifier loss: 1.575187; batch adversarial loss: 0.611195\n",
      "epoch 4; iter: 0; batch classifier loss: 4.453220; batch adversarial loss: 0.671072\n",
      "epoch 4; iter: 200; batch classifier loss: 3.543374; batch adversarial loss: 0.635989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.774815; batch adversarial loss: 0.687947\n",
      "epoch 5; iter: 200; batch classifier loss: 2.594435; batch adversarial loss: 0.624740\n",
      "epoch 6; iter: 0; batch classifier loss: 1.241345; batch adversarial loss: 0.583366\n",
      "epoch 6; iter: 200; batch classifier loss: 0.863850; batch adversarial loss: 0.601183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420315; batch adversarial loss: 0.688266\n",
      "epoch 7; iter: 200; batch classifier loss: 0.400096; batch adversarial loss: 0.641534\n",
      "epoch 8; iter: 0; batch classifier loss: 1.479709; batch adversarial loss: 0.618190\n",
      "epoch 8; iter: 200; batch classifier loss: 0.574372; batch adversarial loss: 0.580982\n",
      "epoch 9; iter: 0; batch classifier loss: 1.018712; batch adversarial loss: 0.643799\n",
      "epoch 9; iter: 200; batch classifier loss: 0.644765; batch adversarial loss: 0.600429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.990478; batch adversarial loss: 0.619350\n",
      "epoch 10; iter: 200; batch classifier loss: 0.593189; batch adversarial loss: 0.590836\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508701; batch adversarial loss: 0.649052\n",
      "epoch 11; iter: 200; batch classifier loss: 0.582827; batch adversarial loss: 0.617925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469438; batch adversarial loss: 0.614250\n",
      "epoch 12; iter: 200; batch classifier loss: 0.443607; batch adversarial loss: 0.606517\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593300; batch adversarial loss: 0.638699\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440661; batch adversarial loss: 0.623696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.478899; batch adversarial loss: 0.628642\n",
      "epoch 14; iter: 200; batch classifier loss: 0.457056; batch adversarial loss: 0.602465\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529009; batch adversarial loss: 0.592314\n",
      "epoch 15; iter: 200; batch classifier loss: 0.518310; batch adversarial loss: 0.613198\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.619762\n",
      "epoch 16; iter: 200; batch classifier loss: 0.511102; batch adversarial loss: 0.587791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307480; batch adversarial loss: 0.631282\n",
      "epoch 17; iter: 200; batch classifier loss: 0.454935; batch adversarial loss: 0.603861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419763; batch adversarial loss: 0.623416\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383531; batch adversarial loss: 0.580715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342738; batch adversarial loss: 0.621056\n",
      "epoch 19; iter: 200; batch classifier loss: 0.343058; batch adversarial loss: 0.574525\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447263; batch adversarial loss: 0.616781\n",
      "epoch 20; iter: 200; batch classifier loss: 0.306838; batch adversarial loss: 0.565687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311157; batch adversarial loss: 0.634948\n",
      "epoch 21; iter: 200; batch classifier loss: 0.413851; batch adversarial loss: 0.560212\n",
      "epoch 22; iter: 0; batch classifier loss: 0.353260; batch adversarial loss: 0.620407\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334654; batch adversarial loss: 0.574214\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354349; batch adversarial loss: 0.594241\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374439; batch adversarial loss: 0.591130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325746; batch adversarial loss: 0.592000\n",
      "epoch 24; iter: 200; batch classifier loss: 0.501993; batch adversarial loss: 0.629855\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333740; batch adversarial loss: 0.607840\n",
      "epoch 25; iter: 200; batch classifier loss: 0.297310; batch adversarial loss: 0.625920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.348885; batch adversarial loss: 0.536905\n",
      "epoch 26; iter: 200; batch classifier loss: 0.259156; batch adversarial loss: 0.639324\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310737; batch adversarial loss: 0.565741\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329312; batch adversarial loss: 0.536320\n",
      "epoch 28; iter: 0; batch classifier loss: 0.271565; batch adversarial loss: 0.569392\n",
      "epoch 28; iter: 200; batch classifier loss: 0.327000; batch adversarial loss: 0.622964\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343799; batch adversarial loss: 0.626436\n",
      "epoch 29; iter: 200; batch classifier loss: 0.286879; batch adversarial loss: 0.642056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336350; batch adversarial loss: 0.622245\n",
      "epoch 30; iter: 200; batch classifier loss: 0.358972; batch adversarial loss: 0.562840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.339758; batch adversarial loss: 0.618464\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331540; batch adversarial loss: 0.574279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.353846; batch adversarial loss: 0.601683\n",
      "epoch 32; iter: 200; batch classifier loss: 0.355241; batch adversarial loss: 0.615449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330047; batch adversarial loss: 0.565490\n",
      "epoch 33; iter: 200; batch classifier loss: 0.311343; batch adversarial loss: 0.613558\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380844; batch adversarial loss: 0.609326\n",
      "epoch 34; iter: 200; batch classifier loss: 0.305435; batch adversarial loss: 0.560929\n",
      "epoch 35; iter: 0; batch classifier loss: 0.338528; batch adversarial loss: 0.623229\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347168; batch adversarial loss: 0.619557\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341614; batch adversarial loss: 0.644722\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327427; batch adversarial loss: 0.636204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381031; batch adversarial loss: 0.604551\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341959; batch adversarial loss: 0.648501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.316701; batch adversarial loss: 0.564693\n",
      "epoch 38; iter: 200; batch classifier loss: 0.329655; batch adversarial loss: 0.637415\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309115; batch adversarial loss: 0.628008\n",
      "epoch 39; iter: 200; batch classifier loss: 0.378563; batch adversarial loss: 0.582520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.263802; batch adversarial loss: 0.655527\n",
      "epoch 40; iter: 200; batch classifier loss: 0.396012; batch adversarial loss: 0.653308\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413995; batch adversarial loss: 0.643959\n",
      "epoch 41; iter: 200; batch classifier loss: 0.352726; batch adversarial loss: 0.612276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.333220; batch adversarial loss: 0.642612\n",
      "epoch 42; iter: 200; batch classifier loss: 0.373309; batch adversarial loss: 0.628992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.277189; batch adversarial loss: 0.622919\n",
      "epoch 43; iter: 200; batch classifier loss: 0.296071; batch adversarial loss: 0.679703\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369003; batch adversarial loss: 0.591501\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389958; batch adversarial loss: 0.648713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318563; batch adversarial loss: 0.592864\n",
      "epoch 45; iter: 200; batch classifier loss: 0.350127; batch adversarial loss: 0.580022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210598; batch adversarial loss: 0.634591\n",
      "epoch 46; iter: 200; batch classifier loss: 0.305697; batch adversarial loss: 0.580900\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286418; batch adversarial loss: 0.592897\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403489; batch adversarial loss: 0.667638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299556; batch adversarial loss: 0.654760\n",
      "epoch 48; iter: 200; batch classifier loss: 0.317408; batch adversarial loss: 0.633405\n",
      "epoch 49; iter: 0; batch classifier loss: 0.305310; batch adversarial loss: 0.654523\n",
      "epoch 49; iter: 200; batch classifier loss: 0.459449; batch adversarial loss: 0.659857\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "# Learn parameters with debias set to True\n",
    "debiased_clf = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "\n",
    "debiased_clf.fit(dataset_orig_train)\n",
    "\n",
    "# Apply the plain model to test data\n",
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_clf.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_clf.predict(dataset_orig_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Plain model - without debiasing - dataset metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.206872\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.201568\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Model - with debiasing - dataset metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.095770\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.092306\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Plain model - without debiasing - classification metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.843374\n",
      "Test set: Balanced classification accuracy = 0.773292\n",
      "Test set: Disparate impact = 0.302917\n",
      "Test set: Equal opportunity difference = -0.140927\n",
      "Test set: Average odds difference = -0.116580\n",
      "Test set: Theil_index = 0.120074\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Model - with debiasing - classification metrics"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.838668\n",
      "Test set: Balanced classification accuracy = 0.736977\n",
      "Test set: Disparate impact = 0.556197\n",
      "Test set: Equal opportunity difference = 0.097225\n",
      "Test set: Average odds difference = 0.039272\n",
      "Test set: Theil_index = 0.141963\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What types of bias mitigation algorithm are available?\n",
    "Bias mitigation algorithms are typically sepparated into preprocessing, inpprocessing,and postprocessig. However,the algorithms within each category can also be very different.\n",
    "### Do you see a difference between the different types of algorithms?\n",
    "### What changes are you able to witness?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Fairness Tools Overview\n",
    "Do a research on other fairness tools that are currently available. What are their use cases? Have some of them been used in the development of commercial products? Take a closer look on at least three other tools.\n",
    "\n",
    ":pencil2: Document your findings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}