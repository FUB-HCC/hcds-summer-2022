{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a5043b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, SampleDistortionMetric,ClassificationMetric,DatasetMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5470714",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ee6ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = load_preproc_data_adult(['race'])\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'race': 1}] # White\n",
    "unprivileged_groups = [{'race': 0}] # Not white"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1aaf74",
   "metadata": {},
   "source": [
    "### Binary Label Dataset Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a016c6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.097328\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f2284",
   "metadata": {},
   "source": [
    "### ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56c8c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train1 = ClassificationMetric(dataset_orig, dataset_orig,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0540774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.101445\n"
     ]
    }
   ],
   "source": [
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train1.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea19f9e",
   "metadata": {},
   "source": [
    "### Dataset Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70771ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train2 = DatasetMetric(dataset_orig,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a76fcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48842.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_orig_train2.num_instances(privileged=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef89178",
   "metadata": {},
   "source": [
    "### SampleDistortionMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73ecc40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train3 = SampleDistortionMetric(dataset_orig,dataset_orig,\n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f30a8113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 1 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 2 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 3 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 4 times so far.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Preprocessing: Objective converged to 0.000000\n"
     ]
    }
   ],
   "source": [
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "    \n",
    "OP = OptimPreproc(OptTools, optim_options)\n",
    "\n",
    "OP = OP.fit(dataset_orig_train)\n",
    "dataset_transf_train = OP.transform(dataset_orig_train, transform_Y=True)\n",
    "\n",
    "dataset_transf_train = dataset_orig_train.align_datasets(dataset_transf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "47b30009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.043280\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefa7bb",
   "metadata": {},
   "source": [
    "#### What types of bias mitigation algorithm are available.\n",
    "\n",
    "Many bias mitigation strategies for machine learning havebeen proposed in recent years. The different approaches can be divided in the following three distinct groups:\n",
    "\n",
    "1. Pre-processing\n",
    "Efficient bias mitigation starts at the data acquisition and processing phase since the source of the data and also the extraction methods can introduce unwanted bias. Therefore, a maximum of effort must be put into validating the integrity of the data source and in ensuring that the data collection process includes appropriate and reliable methods of measurement. Hence, algorithms which belong to the pre-processing family ensure that the input data is balanced and fair. This can be achieved by suppressing the protected attributes, by changing class labels of the data set, and by reweighting or resampling the data.\n",
    "\n",
    "2. In-processing\n",
    "The second type of mitigation strategies comprises the in-processing algorithms. Here, undesired bias is directly mitigated during the training phase. A straightforward approach to achieve this goal is to integrate a fairness penalty directly in the loss function. \n",
    "\n",
    "3. Post-processing\n",
    "The final group of mitigation algorithms follows a post-processing approach. In this case, only the output of a trained classifier is modified. The advantage of post-processing algorithms is that fair classifiers are derived without the necessity of retraining the original model which may be time consuming or difficult to implement in production environments. However, this approach may have a negative effect on accuracy or could compromise any generalization acquired by the original classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad66a1",
   "metadata": {},
   "source": [
    "### Other fairness tools\n",
    "\n",
    "1. RI toolkit - Microsoft responsible innovation toolkit\n",
    ": It provides a set of practices in development, for anticipating and addressing the potential negative impacts of technology on people. There are some tools that can be used to improve fairness. \n",
    "\n",
    "1) Harms Modeling: a framework for product teams, grounded in four core pillars of responsible innovation, that examine how people's lives can be negatively impacted by technology\n",
    "\n",
    "* injuries\n",
    "* denial of consequential services\n",
    "* infringement on human rights\n",
    "* erosion of democratic & societal structures\n",
    "    \n",
    "2) Community Jury: a technique that brings together diverse stakeholders impacted by a technology. It is an adaptation of the citizen jury. The stakeholders are provided an opportunity to learn from experts about a project, deliberate together, and give feedback on use cases and product design. This responsible innovation technique allows project teams to collaborate with researchers to identify stakeholder values, and understand the perceptions and concerns of impacted stakeholders.\n",
    "\n",
    "* Used in 'Center for new democratic processes' \n",
    "* Non-profit\n",
    "\n",
    "2. LIME: Local interpretable model-agnostic explanation. It is developed by a team in University of Washington. It helps to understand the black-box classifier.\n",
    "\n",
    "* It is an effective library to find out if the single prediction was explainable.\n",
    "\n",
    "3. SHAP: it decomposes measures of fairness and allocate responsibility for any observed disparity among each of the modelâ€™s input features. \n",
    "\n",
    "1) Demographic parity metric: the output of the machine learning between the two groups should be equal or comparable. \n",
    "\n",
    "* Compared to the LIME library, it is effective to find out the whole prediction's explainability.\n",
    "* Visualization methods are also available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
